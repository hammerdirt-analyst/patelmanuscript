{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">code group summary --- still testing mostly fucntional</span>\n",
    "\n",
    "### <span style=\"color:red\">Beach litter survey results 2020/2021 Switzerland</span>\n",
    "\n",
    "#### <span style=\"color:#008891\">Definition of significant values</span>\n",
    "\n",
    "#### <span style=\"color:#008891\">National survey result </span>\n",
    "\n",
    "#### <span style=\"color:#008891\">Lac Léman results</span>\n",
    "\n",
    "#### <span style=\"color:#008891\">Lac Léman code group utilisation and availability </span>\n",
    "\n",
    "\n",
    "questions or comments: analyst@hammerdirt.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import datetime as dt \n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# home brew utitilties\n",
    "import utilities.utility_functions as ut\n",
    "\n",
    "# documenting\n",
    "from IPython.display import Markdown as md\n",
    "# from Ipython.core.display import HTML\n",
    "\n",
    "\n",
    "# variables/arrays that are frequently used:\n",
    "# project lakes\n",
    "the_lakes = [\n",
    "    \"Bielersee\",\n",
    "    \"Walensee\",\n",
    "    \"Lac Léman\",\n",
    "    \"Zurichsee\",\n",
    "    \"Neuenburgersee\",\n",
    "    \"Thunersee\",\n",
    "    \"Lago Maggiore\",\n",
    "    \"Brienzersee\",\n",
    "]\n",
    "\n",
    "# standard formats already in use for charts, these will gradually\n",
    "# define the chart style or output format for the app\n",
    "# you can just apply these as kwargs to different elements...\n",
    "\n",
    "\n",
    "# table kwargs\n",
    "table_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=[.5, .5], cellLoc='center')\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center')\n",
    "tabtickp_k = dict(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k20 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "title_k17 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "titler_k20 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "titler_k17 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "ylab_k = {'labelpad':14, 'fontsize':14}\n",
    "titler_k = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12}\n",
    "\n",
    "# use these to format date axis in charts\n",
    "weeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "days = mdates.DayLocator(bymonthday=1, interval=1)\n",
    "months = mdates.MonthLocator(bymonth=[3,6,9,12])\n",
    "wks_fmt = mdates.DateFormatter('%d')\n",
    "mths_fmt = mdates.DateFormatter('%b')\n",
    "\n",
    "# map marker size:\n",
    "markerSize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the local file structure. The resources are located in the corresponding directory.\n",
    "survey_data, location_data, code_defs, stat_ent, geo_data, output = ut.make_local_paths()\n",
    "\n",
    "# set some parameters:\n",
    "start_date = '2020-04-01'\n",
    "end_date = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "year_one = {\"start_date\":\"2015-11-01\", \"end_date\":\"2016-10-31\"}\n",
    "year_two = {\"start_date\":\"2016-11-01\", \"end_date\":\"2017-10-31\"}\n",
    "year_three = {\"start_date\":\"2017-11-01\", \"end_date\":\"2018-10-31\"}\n",
    "year_four = {\"start_date\":\"2018-11-01\", \"end_date\":\"2019-10-31\"}\n",
    "year_five = {\"start_date\":\"2019-11-01\", \"end_date\":\"2020-10-31\"}\n",
    "\n",
    "years = [year_one, year_two, year_three, year_four, year_five]\n",
    "year_names = ['year one', 'year two', 'year three', 'year four', 'year five']\n",
    "\n",
    "\n",
    "# define a code group, there are predefined code groups in\n",
    "# the resources folder under mlwcodedefs\n",
    "const = ut.json_file_get(F\"{output}/code_groups/construction.json\")\n",
    "group_one = ['G27','G35', 'G30', 'G25','G31','G32','G33','G34', 'G21', 'G24']\n",
    "group_one_name = \"kiosk waste\"\n",
    "code = \"gone\"\n",
    "group_names = [group_one_name]\n",
    "\n",
    "# define a second group or leave as all\n",
    "# this note book will only compare the two groups \n",
    "group_two = const\n",
    "group_two_name = 'construction waste'\n",
    "code = \"gtwo\"\n",
    "\n",
    "# keep track of the figures you produce\n",
    "table_num = 1\n",
    "figure_num = 1\n",
    "map_num = 1\n",
    "\n",
    "\n",
    "# choose a lake:\n",
    "lake = 'Lac Léman'\n",
    "\n",
    "# define a significant event:\n",
    "sig = .9\n",
    "one_minus_sig = (1-sig)\n",
    "\n",
    "# define explanatory variables:\n",
    "expv = ['population','streets','buildings','rivs']\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'yearoneThroughFive'\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# probably want to keep these... the works already done\n",
    "# aggregated survey data\n",
    "dfAgg = pd.read_csv(F\"{survey_data}/results_with_zeroes_aggregated_parent.csv\")\n",
    "dfAgg['date'] = pd.to_datetime(dfAgg['date'])\n",
    "# dfAgg['date'] =dfAgg.date.dt.date\n",
    "# dfAgg['date'] = dfAgg.date.strftime(\"%Y-%m-%d\")\n",
    "dfAgg['loc_date'] = list(zip(dfAgg.location, dfAgg.date.dt.strftime('%Y-%m-%d')))\n",
    "dfAgg['loc_date'] = dfAgg.loc_date.map(lambda x: F\"{x}\")\n",
    "dfAgg = dfAgg.loc[(dfAgg.water_name == lake)&(dfAgg.date <= year_five['end_date'])]\n",
    "\n",
    "# non aggregated survey data\n",
    "dfSurveys = pd.read_csv(F\"{survey_data}/results_with_zeroes.csv\")\n",
    "dfSurveys['date'] = pd.to_datetime(dfSurveys['date'])\n",
    "dfSurveys = dfSurveys.loc[dfSurveys.water_name == lake]\n",
    "\n",
    "# beach data\n",
    "dfBeaches = pd.read_csv(F\"{location_data}/beaches_with_ranks.csv\")\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "dfBeaches.rename(columns={\"NUMPOINTS\":\"intersects\"}, inplace=True)\n",
    "dfBeaches = dfBeaches.loc[dfBeaches.water_name == lake]\n",
    "\n",
    "# code definitions\n",
    "dfCodes = pd.read_csv(F\"{code_defs}/mlw_codes.csv\")\n",
    "\n",
    "# geo data: explantory variables, index by slug and make a map:\n",
    "dfStreets = pd.read_csv(F\"{geo_data}/exp_variables/strasse_1000.csv\", index_col='slug')['length']\n",
    "dfBlds = pd.read_csv(F\"{geo_data}/exp_variables/builds_500.csv\", index_col='slug')['surface']\n",
    "dfRivs = dfBeaches['intersects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kiosk waste_dt', 'construction waste_dt', 'the rest_dt', 'survey total_dt']\n",
      "dict_keys(['kiosk waste', 'construction waste', 'the rest', 'kiosk waste_dt', 'construction waste_dt', 'the rest_dt', 'survey total_dt'])\n"
     ]
    }
   ],
   "source": [
    "# restrict to lakes only\n",
    "dfS = dfAgg\n",
    "\n",
    "# map geo values to survey results:\n",
    "dfS['population']=dfS.location.map(lambda x: dfBeaches.loc[x]['population'])\n",
    "dfS['streets'] = dfS.location.map(lambda x: dfStreets.loc[x])\n",
    "dfS['buildings'] = dfS.location.map(lambda x: dfBlds.loc[x])\n",
    "dfS['rivs'] = dfS.location.map(lambda x: dfRivs.loc[x])\n",
    "\n",
    "# get a list of the codes in the current data\n",
    "codes_in_use = dfS.code.unique()\n",
    "\n",
    "# seperate out group_one:\n",
    "dfGone = dfS.loc[dfS.code.isin(group_one)].copy()\n",
    "\n",
    "# group all the codes in group 2 or all the codes not in group one\n",
    "if 'all' in group_two:\n",
    "    dfGtwo = dfS.loc[~dfS.code.isin(group_one)].copy()\n",
    "    group_two_name = 'the rest'\n",
    "else:\n",
    "    dfGtwo = dfS.loc[dfS.code.isin(group_two)].copy()\n",
    "\n",
    "group_names.append(group_two_name)\n",
    "\n",
    "# gather up the created dataframes\n",
    "groupdfs = [dfGone,dfGtwo]\n",
    "\n",
    "# get the codes that have been accounted for in groupone and grouptwo:\n",
    "codes_accounted_for = set(list(dfGone.code.unique())) | set(list(dfGtwo.code.unique()))\n",
    "\n",
    "# get the codes that have not been accounted for\n",
    "group_three = [x for x in codes_in_use if x not in codes_accounted_for]\n",
    "\n",
    "# make a boolean to alert to the presence of data in group three\n",
    "# if you choose all as the second group then groupthree will be empty\n",
    "gthree = len(group_three) > 0\n",
    "\n",
    "# keep track of the files you are exporting:\n",
    "files_generated = []\n",
    "\n",
    "# save files\n",
    "survey_csv = F\"{project_directory}/survey_data.csv\"\n",
    "files_generated.append(survey_csv)\n",
    "dfS.to_csv(survey_csv, index=False)\n",
    "\n",
    "beaches_csv = F\"{project_directory}/beach_data.csv\"\n",
    "files_generated.append(beaches_csv)\n",
    "dfBeaches.to_csv(beaches_csv, index=False)\n",
    "\n",
    "# daily totals for each group\n",
    "# and assign the name 'rest' to either group_two or group_three\n",
    "# that depends on the value of group_two\n",
    "if gthree:\n",
    "    group_three_name = 'the rest'\n",
    "    dfGthree = dfS.loc[dfS.code.isin(group_three)].copy()\n",
    "    project_groups = [group_one, group_two, group_three]\n",
    "    group_names.append(group_three_name)\n",
    "    groupdfs.append(dfGthree)\n",
    "else:\n",
    "    project_groups = [group_one, group_two]\n",
    "\n",
    "# put the dfs in a dictionary and key to group name\n",
    "groupdfs = {x:groupdfs[i] for i,x in enumerate(group_names)}\n",
    "# daily totals for each group\n",
    "# name the columns to keep when aggregating:\n",
    "cols_to_keep = ['loc_date','location','water_name', 'date','population','streets','buildings','rivs']\n",
    "\n",
    "# get the daily total for each group and store in a data frame:\n",
    "for name in group_names:\n",
    "    new_name = F\"{name}_dt\"\n",
    "    dtdf = groupdfs[name].groupby(cols_to_keep, as_index=False).agg({\"pcs_m\":\"sum\", \"quantity\":\"sum\"})    \n",
    "    dtdf.set_index('loc_date', inplace=True)\n",
    "    groupdfs.update({new_name:dtdf})\n",
    "\n",
    "# get each survey total per location and date (all codes included)\n",
    "# we can check combined values with this\n",
    "allDf = dfS.groupby(['loc_date','location','water_name', 'date','population','streets','buildings','rivs'], as_index=False).agg({\"pcs_m\":\"sum\", \"quantity\":\"sum\"})\n",
    "allDf.set_index('loc_date', inplace=True)\n",
    "\n",
    "# add that to the collection of dataframes\n",
    "groupdfs.update({\"survey total_dt\":allDf})\n",
    "group_names.append(\"survey total\")\n",
    "groupkeys = groupdfs.keys()\n",
    "\n",
    "# get the percent of survey total for each group\n",
    "dt_names = [F\"{name}_dt\" for name in group_names]\n",
    "print(dt_names)\n",
    "print(groupdfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "('arabie', '2016-01-24')\n",
      "('arabie', '2016-01-24')\n",
      "dict_keys(['kiosk waste', 'construction waste', 'the rest', 'kiosk waste_dt', 'construction waste_dt', 'the rest_dt', 'survey total_dt'])\n",
      "Index(['location', 'water_name', 'date', 'population', 'streets', 'buildings',\n",
      "       'rivs', 'pcs_m', 'quantity', 'p_total'],\n",
      "      dtype='object')\n",
      "204\n",
      "['anarchy-beach' 'arabie' 'baby-plage-geneva' 'bain-des-dames'\n",
      " 'baye-de-clarens' 'baye-de-montreux-d' 'baye-de-montreux-g' 'boiron'\n",
      " 'cully-plage' 'grand-clos' 'jardin-botanique' 'la-morges' 'la-pecherie'\n",
      " 'lac-leman-hammerdirt' 'lacleman_gland_kubela' 'lacleman_gland_lecoanets'\n",
      " 'lacleman_vidy_santie' 'le-pierrier' 'le-port' 'maladaire' 'oyonne'\n",
      " 'parc-des-pierrettes' 'pierrier-sud' 'plage-de-dorigny'\n",
      " 'plage-de-st-sulpice' 'preverenges' 'quai-maria-belgia' 'rolle-plage'\n",
      " 'saint-sulpice' 'tiger-duck-beach' 'tolochenaz' 'versoix' 'veveyse'\n",
      " 'vidy' 'vidy-ruines' 'villa-barton']\n"
     ]
    }
   ],
   "source": [
    "print(type(groupdfs['kiosk waste_dt'].index[1][1]))\n",
    "print(groupdfs['kiosk waste_dt'].index[1])\n",
    "type(groupdfs[\"survey total_dt\"].index[1][1])\n",
    "print(groupdfs[\"survey total_dt\"].index[1])\n",
    "\n",
    "for name in dt_names:\n",
    "    groupdfs[name][\"p_total\"] = groupdfs[name].index.map(lambda x: groupdfs[name].loc[x].pcs_m/groupdfs[\"survey total_dt\"].loc[x].pcs_m)\n",
    "    groupdfs[name]['p_total'] = groupdfs[name]['p_total']*100\n",
    "    groupdfs[name]['p_total'] = groupdfs[name]['p_total'].round(2)\n",
    "\n",
    "print(groupdfs.keys())\n",
    "print(allDf.columns)\n",
    "dftotal = groupdfs['survey total_dt']\n",
    "print(len(dftotal))\n",
    "print(dftotal.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_in_date_group(x, groups):\n",
    "    for i,group in enumerate(groups):\n",
    "        this_date = dt.datetime.strptime(group[1], '%Y-%m-%d')\n",
    "#         print(type(x))\n",
    "        if x < this_date:\n",
    "            this_group = i\n",
    "            break\n",
    "        else:\n",
    "            this_group = i\n",
    "    \n",
    "    return this_group\n",
    "date_tuples = [(v['start_date'], v['end_date']) for v in years ]\n",
    "\n",
    "for name in dt_names:\n",
    "    groupdfs[name][\"year\"] = groupdfs[name].date.map(lambda x: put_in_date_group(x, date_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3 4]\n",
      "   year  loc_date\n",
      "0     0        81\n",
      "1     1        41\n",
      "2     2        24\n",
      "3     3         4\n",
      "4     4        54\n",
      "           date           \n",
      "            min        max\n",
      "year                      \n",
      "0    2015-11-23 2016-10-13\n",
      "1    2016-11-14 2017-10-26\n",
      "2    2017-11-11 2018-10-16\n",
      "3    2018-11-06 2019-10-24\n",
      "4    2020-04-28 2020-10-29\n"
     ]
    }
   ],
   "source": [
    "print(groupdfs[dt_names[0]].year.unique())\n",
    "groupdfs[dt_names[0]].reset_index(inplace=True)\n",
    "print(groupdfs[dt_names[0]].groupby('year', as_index=False).loc_date.count())\n",
    "print(groupdfs[dt_names[0]].groupby('year').agg({'date':['min','max']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_data = groupdfs['survey total_dt'].copy()\n",
    "this_data['group'] = this_data.year + 1\n",
    "this_agg = {'loc_date':'count', 'location':'nunique', 'pcs_m':['median', 'mean'],  'quantity':'sum'}\n",
    "this_data.reset_index(inplace=True)\n",
    "regional_summary = this_data.groupby('group', as_index=False).agg(this_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "sns.boxplot(data=this_data, x='group', y='pcs_m', hue='group', dodge=False, ax=ax)\n",
    "\n",
    "# ax.legend(loc)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 1, 0, 0, 1]), array([3, 1, 1, 0, 0, 5]), array([0, 0, 0, 1, 5, 6]), array([1, 1, 1, 0, 1, 4]), array([13,  0,  0,  0,  0, 13]), array([15,  1,  0,  0,  0, 16]), array([11,  1,  0,  0,  6, 18]), array([1, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([1, 1, 0, 0, 6, 8]), array([3, 0, 0, 0, 0, 3]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 2, 2]), array([0, 1, 0, 0, 0, 1]), array([ 0,  6,  5,  0,  0, 11]), array([ 0,  4,  5,  0,  2, 11]), array([ 0,  7,  5,  0,  0, 12]), array([3, 1, 0, 0, 0, 4]), array([1, 0, 0, 0, 0, 1]), array([2, 0, 0, 0, 6, 8]), array([1, 1, 0, 0, 0, 2]), array([1, 1, 0, 1, 1, 4]), array([1, 0, 0, 0, 0, 1]), array([0, 1, 0, 0, 0, 1]), array([1, 1, 0, 0, 1, 3]), array([0, 0, 2, 0, 5, 7]), array([ 0,  7,  3,  0,  7, 17]), array([0, 0, 0, 1, 0, 1]), array([0, 0, 0, 1, 0, 1]), array([0, 0, 1, 0, 2, 3]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 3, 4]), array([13,  4,  0,  0,  0, 17]), array([1, 0, 0, 0, 0, 1]), array([0, 0, 0, 0, 4, 4]), array([ 9,  0,  0,  0,  1, 10]), array([ 81,  41,  24,   4,  54, 204])]\n"
     ]
    }
   ],
   "source": [
    "these_beaches = this_data.location.unique()\n",
    "surveys_year = pd.DataFrame({'location':these_beaches})\n",
    "grouped_by_year=this_data.groupby(['group','location']).loc_date.count()\n",
    "grouped_by_year.loc[1]\n",
    "\n",
    "def count_per_year(x,group):\n",
    "    try:\n",
    "        count = grouped_by_year.loc[group][x]\n",
    "    except:\n",
    "        count = 0\n",
    "    return count\n",
    "surveys_year.set_index('location', inplace=True, drop=True)\n",
    "\n",
    "for i, name in enumerate(year_names):\n",
    "    surveys_year[name] = surveys_year.index.map(lambda x: count_per_year(x, i+1))\n",
    "\n",
    "\n",
    "surveys_year.loc[:, 'total'] = surveys_year[['year one', 'year two', 'year three', 'year four', 'year five']].sum(axis=1)\n",
    "last_row = surveys_year.sum(axis=0).values\n",
    "table_data = list(surveys_year.values)\n",
    "table_data.append(last_row)\n",
    "print(table_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year one</th>\n",
       "      <th>year two</th>\n",
       "      <th>year three</th>\n",
       "      <th>year four</th>\n",
       "      <th>year five</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anarchy-beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arabie</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby-plage-geneva</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bain-des-dames</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baye-de-clarens</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baye-de-montreux-d</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baye-de-montreux-g</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boiron</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cully-plage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grand-clos</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jardin-botanique</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la-morges</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la-pecherie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lac-leman-hammerdirt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacleman_gland_kubela</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacleman_gland_lecoanets</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacleman_vidy_santie</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le-pierrier</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le-port</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maladaire</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyonne</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parc-des-pierrettes</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pierrier-sud</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plage-de-dorigny</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plage-de-st-sulpice</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preverenges</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quai-maria-belgia</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolle-plage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saint-sulpice</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger-duck-beach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolochenaz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versoix</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veveyse</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vidy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vidy-ruines</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villa-barton</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          year one  year two  year three  year four  \\\n",
       "location                                                              \n",
       "anarchy-beach                    0         0           1          0   \n",
       "arabie                           3         1           1          0   \n",
       "baby-plage-geneva                0         0           0          1   \n",
       "bain-des-dames                   1         1           1          0   \n",
       "baye-de-clarens                 13         0           0          0   \n",
       "baye-de-montreux-d              15         1           0          0   \n",
       "baye-de-montreux-g              11         1           0          0   \n",
       "boiron                           1         0           0          0   \n",
       "cully-plage                      0         0           0          0   \n",
       "grand-clos                       1         1           0          0   \n",
       "jardin-botanique                 3         0           0          0   \n",
       "la-morges                        0         1           0          0   \n",
       "la-pecherie                      0         0           0          0   \n",
       "lac-leman-hammerdirt             0         1           0          0   \n",
       "lacleman_gland_kubela            0         6           5          0   \n",
       "lacleman_gland_lecoanets         0         4           5          0   \n",
       "lacleman_vidy_santie             0         7           5          0   \n",
       "le-pierrier                      3         1           0          0   \n",
       "le-port                          1         0           0          0   \n",
       "maladaire                        2         0           0          0   \n",
       "oyonne                           1         1           0          0   \n",
       "parc-des-pierrettes              1         1           0          1   \n",
       "pierrier-sud                     1         0           0          0   \n",
       "plage-de-dorigny                 0         1           0          0   \n",
       "plage-de-st-sulpice              1         1           0          0   \n",
       "preverenges                      0         0           2          0   \n",
       "quai-maria-belgia                0         7           3          0   \n",
       "rolle-plage                      0         0           0          1   \n",
       "saint-sulpice                    0         0           0          1   \n",
       "tiger-duck-beach                 0         0           1          0   \n",
       "tolochenaz                       0         0           0          0   \n",
       "versoix                          0         1           0          0   \n",
       "veveyse                         13         4           0          0   \n",
       "vidy                             1         0           0          0   \n",
       "vidy-ruines                      0         0           0          0   \n",
       "villa-barton                     9         0           0          0   \n",
       "\n",
       "                          year five  total  \n",
       "location                                    \n",
       "anarchy-beach                     0      1  \n",
       "arabie                            0      5  \n",
       "baby-plage-geneva                 5      6  \n",
       "bain-des-dames                    1      4  \n",
       "baye-de-clarens                   0     13  \n",
       "baye-de-montreux-d                0     16  \n",
       "baye-de-montreux-g                6     18  \n",
       "boiron                            0      1  \n",
       "cully-plage                       1      1  \n",
       "grand-clos                        6      8  \n",
       "jardin-botanique                  0      3  \n",
       "la-morges                         0      1  \n",
       "la-pecherie                       2      2  \n",
       "lac-leman-hammerdirt              0      1  \n",
       "lacleman_gland_kubela             0     11  \n",
       "lacleman_gland_lecoanets          2     11  \n",
       "lacleman_vidy_santie              0     12  \n",
       "le-pierrier                       0      4  \n",
       "le-port                           0      1  \n",
       "maladaire                         6      8  \n",
       "oyonne                            0      2  \n",
       "parc-des-pierrettes               1      4  \n",
       "pierrier-sud                      0      1  \n",
       "plage-de-dorigny                  0      1  \n",
       "plage-de-st-sulpice               1      3  \n",
       "preverenges                       5      7  \n",
       "quai-maria-belgia                 7     17  \n",
       "rolle-plage                       0      1  \n",
       "saint-sulpice                     0      1  \n",
       "tiger-duck-beach                  2      3  \n",
       "tolochenaz                        1      1  \n",
       "versoix                           3      4  \n",
       "veveyse                           0     17  \n",
       "vidy                              0      1  \n",
       "vidy-ruines                       4      4  \n",
       "villa-barton                      1     10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3c22a87d5839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlakes_with\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasGpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mregional_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations with'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregional_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mF\"{lakes_with.loc[x].location}/{regional_summary.loc[x].location}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# rename the columns to ui style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   4792\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4794\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4796\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3c22a87d5839>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlakes_with\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasGpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mregional_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations with'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregional_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mF\"{lakes_with.loc[x].location}/{regional_summary.loc[x].location}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# rename the columns to ui style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3489\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3491\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# summarize the results by lake.\n",
    "# Number of locations and surveys with or without code for each lake\n",
    "# Make column headers plain english, make table\n",
    "\n",
    "# place to store the summaries\n",
    "regional_summaries = []\n",
    "\n",
    "# creating a summary for each df in groupdfs\n",
    "for name in dt_names:\n",
    "    this_data = groupdfs[name]\n",
    "    this_agg = {'loc_date':'count', 'location':'nunique', 'pcs_m':'median', 'p_total':'mean'}\n",
    "    this_data.reset_index(inplace=True)\n",
    "    regional_summary = this_data.groupby('year').agg(this_agg)\n",
    "    regions = list(regional_summary.index)\n",
    "    \n",
    "    # the mean of all the group data \n",
    "    rs_mean = this_data.groupby('year').pcs_m.mean()\n",
    "    \n",
    "    # the number of samples with group pcs_m > 0\n",
    "    regional_summary[\"# samps with\"] = regional_summary.index.map(lambda x: F\"{this_data[(this_data.water_name == x)&(this_data.pcs_m > 0)].pcs_m.count()}/{this_data[this_data.water_name == x].loc_date.nunique()}\")\n",
    "    \n",
    "    hasGpi = this_data[this_data.quantity > 0]\n",
    "    # count the number of locations with the code value per lake\n",
    "    lakes_with = hasGpi[['water_name', 'location']].groupby(['water_name']).nunique('location')\n",
    "    \n",
    "    regional_summary['locations with'] = regional_summary.index.map(lambda x: F\"{lakes_with.loc[x].location}/{regional_summary.loc[x].location}\")\n",
    "    \n",
    "    # rename the columns to ui style\n",
    "    new_columns = {'loc_date':'# samples',\n",
    "                   \"locations with\":\"# with\",\n",
    "                   'location':'# locations',\n",
    "                   \"pcs_m\":\"median pcs/m\",\n",
    "                   \"p_total\":\"% of daily total\"\n",
    "                  }\n",
    "    regional_summary.rename(columns=new_columns, inplace=True)\n",
    "    \n",
    "    # add the pcs/m per region:\n",
    "    regional_summary['mean pcs/m'] = regional_summary.index.map(lambda x: rs_mean[x])\n",
    "    col_order = [\"# locations\", \"# with\",\"# samples\", \"# samps with\", \"median pcs/m\", \"mean pcs/m\", \"% of daily total\"]\n",
    "    regional_summary = regional_summary[col_order]\n",
    "    \n",
    "    # reset the index, we need the index for a column in the table\n",
    "    regional_summary.reset_index(inplace=True)\n",
    "\n",
    "    # make a column name for the former index:\n",
    "    regional_summary.rename(columns={'water_name':'lake'}, inplace=True)\n",
    "\n",
    "    # round any values:\n",
    "    regional_summary['mean pcs/m'] = regional_summary['mean pcs/m'].round(3)\n",
    "    regional_summary[\"median pcs/m\"] = regional_summary[\"median pcs/m\"].round(3)\n",
    "    regional_summary[\"% of daily total\"] = regional_summary[\"% of daily total\"].round(2)\n",
    "    regional_summaries.append({'data':regional_summary.values, 'cols':regional_summary.columns})\n",
    "\n",
    "# significant values\n",
    "# use the ECDF method from statsmodels to get the ecdf function for the different data frames\n",
    "# pieces per meter\n",
    "pmecdfs = {}\n",
    "for name in dt_names:\n",
    "    somdata = groupdfs[name]\n",
    "    thisecdf = ECDF(somdata['pcs_m'])\n",
    "    pmecdfs.update({name:thisecdf})\n",
    "    somdata['p_dt'] = somdata.pcs_m.map(lambda x: 1-thisecdf(x))\n",
    "    somdata['significant'] = somdata.p_dt.map(lambda x: x <= one_minus_sig)\n",
    "    \n",
    "ptecdfs = {}\n",
    "for name in dt_names:\n",
    "    somdata = groupdfs[name]\n",
    "    thisecdf = ECDF(somdata['p_total'])    \n",
    "    ptecdfs.update({name:thisecdf})\n",
    "    somdata['p_pt'] = somdata.p_total.map(lambda x: 1-thisecdf(x))\n",
    "    somdata['significant_p'] = somdata.p_pt.map(lambda x: x <= one_minus_sig)\n",
    "\n",
    "events_data = {}\n",
    "for name in dt_names:\n",
    "    somdata = groupdfs[name]\n",
    "    p_dt90 = somdata[somdata.significant == True].groupby(['water_name'], as_index=False).loc_date.nunique()\n",
    "    p_dt90['frequency'] = p_dt90.water_name.map(lambda x: (F\"{p_dt90.loc[p_dt90.water_name == x]['loc_date'].values[0]}/{regional_summary.loc[regional_summary.lake == x]['# samples'].values[0]}\"))\n",
    "    p_dt90.rename(columns={'loc_date':'# significant','water_name': 'lake'}, inplace=True)\n",
    "    events_data.update({name:p_dt90})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\">Methods</span>\n",
    "\n",
    "#### **<span style=\"color:#008891\">Data source, time frame, geographic scope and collection methods </span>**\n",
    "\n",
    "The data for this analysis is the results from beach-litter surveys conducted in Switzerland from <span style=\"color:red\">!! Put your dates here !! through January 18, 2021</span>.\n",
    "\n",
    "All surveys that were conducted on Bielersee, Neuenburgersee, Thunersee, Walensee, Zurichsee, Lac Léman, Brienzersee and Lago Magiore were considered. \n",
    "\n",
    "The data was collected according to the protocol described here [https://www.plagespropres.ch/](https://www.plagespropres.ch/). In brief all visible data is collected along a beach within a measured distance from the waters edge. The width of the survey area depends on the terrain and the water level. The visible strand line or the nearest physical structure defines the width of a survey.\n",
    "\n",
    "Surveys were conducted by the following organizations:\n",
    "\n",
    "1. hammerdirt\n",
    "2. Association pour le Sauvegarde du leman\n",
    "3. Solid Waste Management Ecole Polytechnique Federal\n",
    "4. Ecole International de Geneve\n",
    "5. Precious plastic leman\n",
    "6. Why isn't your association here?\n",
    "\n",
    "This analysis is an open source document. The working note book is available in the repository located here [https://github.com/hammerdirt-analyst/iqals](https://github.com/hammerdirt-analyst/iqals).\n",
    "\n",
    "**Francais**\n",
    "\n",
    "Les données utilisées pour cette analyse sont les résultats d'enquêtes sur les déchets de plage menées en Suisse <span style=\"color:red\">!! put your dates here !! du 1er avril 2020 au 28  janvier 2021</span>.\n",
    "\n",
    "Toutes les enquêtes qui ont été menées sur le lac de Bienne, le lac de Neuchâtel, le lac de Thoune, le lac Walensee, le lac de Zurich, le lac Léman, le lac Brienzer et le lac Magiore ont été prises en compte. \n",
    "\n",
    "Les données ont été collectées selon le protocole décrit ici [https://www.plagespropres.ch/](https://www.plagespropres.ch/). En bref, toutes les données visibles sont collectées le long d'une plage à une distance mesurée du bord de l'eau. La largeur de la zone d'étude dépend du terrain et du niveau de l'eau. La ligne de rive visible ou la structure physique la plus proche définit la largeur d'une enquête.\n",
    "\n",
    "Des enquêtes ont été menées par:\n",
    "\n",
    "1. hammerdirt\n",
    "2. Association pour le Sauvegarde du leman\n",
    "3. Solid Waste Management Ecole Polytechnique Federal\n",
    "4. Ecole International de Geneve\n",
    "5. Precious plastic leman\n",
    "6. Why isn't your association here?1. hammerdirt\n",
    "\n",
    "Cette analyse est un document open source. Le cahier de notes de travail est disponible dans le dépôt situé ici: [https://github.com/hammerdirt-analyst/iqals](https://github.com/hammerdirt-analyst/iqals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Scope of surveys</span>\n",
    "\n",
    "The scope of the surveys includes the total population levels and land use configuration for the adjacent municipality. Land use is quantified by calculating the m² of space attributed to buildings wtihin 500m of the survey location and the total length in meters of roads within 1000m of the survey location\\*.\n",
    "\n",
    "The results and survey locations can be classified according to the following attributes:\n",
    "\n",
    "1. M² of buildings within 500m of the survey\n",
    "2. Total length of streets/roads within 1000m of the survey\n",
    "3. Number of river/canal intersections within 1500m of the survey\n",
    "3. Population of the surounding municipality\n",
    "\n",
    "\\*Values are calculated using [https://shop.swisstopo.admin.ch/en/products/landscape/tlm3D](https://shop.swisstopo.admin.ch/en/products/landscape/tlm3D)\n",
    "\n",
    "**Français**\n",
    "\n",
    "Le champ d'application des enquêtes comprend les niveaux de population totale et la configuration de l'utilisation des sols pour la municipalité environante. L'utilisation des sols est quantifiée en calculant la superficie en m² attribuée aux bâtiments dans un rayon de 500 m du lieu de l'enquête et la longueur totale en mètres des routes dans un rayon de 1000 m du lieu de l'enquête\\*.\n",
    "\n",
    "Les résultats et les lieux d'enquête peuvent être classés selon les attributs suivants :\n",
    "\n",
    "1. M² de surface au sol des bâtiments situés dans un rayon de 500m du lieu d'enquête\n",
    "2. Longueur totale des rues/routes dans un rayon de 1000 m de l'enquête\n",
    "3. Nombre d'intersections de rivières/canaux dans un rayon de 1500m de l'étude\n",
    "3. Population de la commune environnante\n",
    "\n",
    "Les valeurs sont calculées en utilisant  [https://shop.swisstopo.admin.ch/en/products/landscape/tlm3D](https://shop.swisstopo.admin.ch/en/products/landscape/tlm3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Attribute values and survey totals</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure one total survey pcs/m per attribute value:\n",
    "\n",
    "\n",
    "# key the column names to appropriate chart titles:\n",
    "titles_text = {\n",
    "    'population':'Municipal population',\n",
    "    'streets': 'Meters of roads/streets',\n",
    "    'buildings':'Meters squared of buildings',\n",
    "    'rivs':'River/canal intersection',\n",
    "    \n",
    "}\n",
    "\n",
    "# produce a chart for each explanatory variable and each group\n",
    "for i,name in enumerate(dt_names):\n",
    "    fig, axs = plt.subplots(1,len(expv), figsize=(14,4), sharey=True)\n",
    "    for j,att in enumerate(expv):\n",
    "        data = groupdfs[name][['water_name','pcs_m', att]]\n",
    "        ax = sns.scatterplot(data=data, x=att, y='pcs_m', hue='water_name', palette='husl', alpha=0.8, ax=axs[j])\n",
    "        axs[j].set_title(F\"{name[:-3]} {att}\", **title_k)\n",
    "        axs[j].set_xlabel(titles_text[att], **xlab_k)\n",
    "        axs[j].set_ylabel('')\n",
    "        axs[j].get_legend().remove()\n",
    "    axs[0].set_ylabel('Survey total pieces per meter', **xlab_k)\n",
    "#     handles, labels =  axs[i].get_legend_handles_labels()\n",
    "#     plt.legend(handles, labels)\n",
    "    plt.suptitle(F\"Figure {figure_num}: survey total by attribute and lake: {end_date}\", x=0.02, y=0.99, ha='left')\n",
    "    figure_num += 1\n",
    "    # save that\n",
    "    figureonefile = F\"{project_directory}/figure{figure_num}.jpg\"\n",
    "    files_generated.append(figureonefile)\n",
    "    plt.savefig(figureonefile, dpi=300)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculator: what ever other metric that needs to be calculated\n",
    "# shoud be calculated here. Then they can be used in the narrative\n",
    "# or applied to the regional results. Good place to look at\n",
    "# correlation tables with geo data\n",
    "\n",
    "# group by location and get the total found\n",
    "# qGpi = dfCode.groupby(['location', 'water_name'], as_index=False).quantity.sum()\n",
    "\n",
    "# seperate locations with or wothout the code\n",
    "# noGpi = qGpi[qGpi.quantity == 0]\n",
    "# hasGpi = qGpi[qGpi.quantity > 0]\n",
    "\n",
    "# count the number of locations with the code value per lake\n",
    "# lakes_with = hasGpi[['water_name', 'location']].groupby(['water_name']).nunique('location')\n",
    "\n",
    "# total gpi found and percent of total\n",
    "# numg112 = dfS[dfS.code.isin(group_one)].quantity.sum()\n",
    "# numtotal = dfS.quantity.sum()\n",
    "# g112_p_total = numg112/numtotal\n",
    "\n",
    "# Frequency, surveys with code \n",
    "# qGpiD = dfCode.groupby(['location', 'water_name','loc_date', 'date'], as_index=False).pcs_m.sum()\n",
    "# number_trys = len(qGpiD)\n",
    "# number_fail = sum(qGpiD.pcs_m == 0)\n",
    "# number_succ = len(qGpiD[qGpiD.pcs_m > 0])\n",
    "# print(\"CODE total values\")\n",
    "# print(numg112)\n",
    "# print(numtotal)\n",
    "# print(g112_p_total)\n",
    "\n",
    "# print(\"CODE trys and fails\")\n",
    "# print(number_trys)\n",
    "# print(number_fail)\n",
    "# print(number_succ)\n",
    "\n",
    "# correlation with geo variables\n",
    "# combining streets and buildings could be interesting:\n",
    "\n",
    "# g112Df['combined'] = g112Df.streets + g112Df.buildings\n",
    "\n",
    "# g112Df[['population', 'streets', 'buildings', 'rivs','combined', 'p_total', ]].corr('spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Geographic scope of surveys</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shapes\n",
    "gdf = gpd.read_file('resources/shapes/riparian_communities.shp')\n",
    "gdfch = gpd.read_file('resources/shapes/ch.shp')\n",
    "gdflakes = gpd.read_file('resources/shapes/project_lakes.shp')\n",
    "\n",
    "# make point layers, add survey results\n",
    "\n",
    "# get the beaches from the location column of the data\n",
    "beaches = dfBeaches.loc[dfBeaches.index.isin(groupdfs[\"dfDtAll\"].location.unique())].copy()\n",
    "\n",
    "# create map the median pcs/m to location\n",
    "median_map = groupdfs[\"dfDtAll\"].groupby('location').pcs_m.median().copy()\n",
    "\n",
    "# apply the map to the beach data:\n",
    "beaches['pcs_m'] = beaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "# port to gpd and reproject to the correct crs:\n",
    "gbeaches = gpd.GeoDataFrame(beaches, crs='EPSG:4326', geometry=gpd.points_from_xy(beaches.longitude, beaches.latitude))\n",
    "gdbeaches = gbeaches.to_crs(gdf.crs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,12))\n",
    "axs.set_aspect('equal')\n",
    "\n",
    "# plot the shapes and points:\n",
    "gdfch.plot(ax=axs, zorder=0, color='white', edgecolor='black', linewidth=0.26)\n",
    "gdf.plot(ax=axs, zorder=1, color='white', edgecolor='black', label='riparian coumminities', linewidth=0.26)\n",
    "gdflakes.plot(ax=axs, zorder=2, color='dodgerblue', edgecolor='white', linewidth=0.26)\n",
    "gdbeaches.plot(ax=axs, zorder=3, color='red', edgecolor='black',marker='o', label='survey locataions',  markersize=80)\n",
    "\n",
    "# get and set the bounds\n",
    "minx, miny, maxx, maxy = gdfch.total_bounds\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "axs.set_title(F\"Map {map_num}: Survey locations {end_date}.\", **title_k)\n",
    "axs.set_xlim(minx, maxx)\n",
    "axs.set_ylim(miny, maxy)\n",
    "map_num + 1\n",
    "\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, labels)\n",
    "plt.tight_layout()\n",
    "\n",
    "maponefile = F\"{project_directory}/mapone.jpg\"\n",
    "files_generated.append(maponefile)\n",
    "plt.savefig(maponefile, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\">Survey results</span>\n",
    "(table 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make summary of data and put to table:\n",
    "# summarize the total pcs/m per survey\n",
    "# use pd.describe and omit the first element (count)\n",
    "sum_tables = []\n",
    "for name in dt_names:\n",
    "    a_row = list(groupdfs[name].pcs_m.describe().index[1:])\n",
    "    a_data = [[np.round(groupdfs[name].pcs_m.describe()[i], 2)] for i in a_row]\n",
    "    one_table = {'data':a_data, 'a_row':a_row, 'name':name}\n",
    "    sum_tables.append(one_table)\n",
    "sum_tables[2]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(sum_tables), figsize=(8,8))\n",
    "\n",
    "for i, table in enumerate(sum_tables):\n",
    "    axs[i].spines[\"top\"].set_visible(False)\n",
    "    axs[i].spines[\"right\"].set_visible(False)\n",
    "    axs[i].spines[\"bottom\"].set_visible(False)\n",
    "    axs[i].spines[\"left\"].set_visible(False)\n",
    "    axs[i].grid(False)\n",
    "    axs[i].add_table(\n",
    "        mpl.table.table(\n",
    "            cellText=table['data'],\n",
    "            rowLabels=table['a_row'],\n",
    "            colLabels=['Summary'],\n",
    "            colColours=['antiquewhite' for i in np.arange(1)],\n",
    "            rowColours=['antiquewhite' for i in np.arange(len(table['a_row']))],\n",
    "            ax=axs[i],\n",
    "            **tablecenter_k))\n",
    "    axs[i].tick_params(**tabtickp_k)\n",
    "    axs[i].set_title(F\"Table {table_num}: {table['name'][:-3]}\", **title_k)\n",
    "    table_num += 1\n",
    "    \n",
    "\n",
    "plt.suptitle(F\"Survey results, key values {end_date}, n={len(groupdfs['dfDtAll'])}\", x=.5, y=0.98, ha='center', fontsize=(14))\n",
    "tableonefile = F\"{project_directory}/tableone.jpg\"\n",
    "files_generated.append(tableonefile)\n",
    "plt.savefig(tableonefile, dpi=300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Regional summary</span>\n",
    "\n",
    "(table 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust table args if need:\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=12)\n",
    "\n",
    "fig, axs = plt.subplots(len(regional_summaries), 1, figsize=(14,16))\n",
    "\n",
    "for i, name in enumerate(dt_names):\n",
    "    axs[i].add_table(mpl.table.table(cellText=regional_summaries[i]['data'] , colLabels=regional_summaries[i]['cols'],colColours=['antiquewhite' for col in regional_summaries[i]['cols']], ax=axs[i], **tablecenter_k))\n",
    "    axs[i].grid(False)\n",
    "    axs[i].spines[\"top\"].set_visible(False)\n",
    "    axs[i].spines[\"right\"].set_visible(False)\n",
    "    axs[i].spines[\"bottom\"].set_visible(False)\n",
    "    axs[i].spines[\"left\"].set_visible(False)\n",
    "    axs[i].tick_params(**tabtickp_k)\n",
    "    axs[i].set_title(F\"Table {table_num}: Regional survey results, {name[:-3]}\", **titler_k)\n",
    "    table_num += 1\n",
    "\n",
    "# tabletwofile = F\"{project_directory}/tabletwo.jpg\"\n",
    "# files_generated.append(tabletwofile)\n",
    "# plt.savefig(tabletwofile, dpi=300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#008891\">Distribution of survey results</span>\n",
    "(fig 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_median = {}\n",
    "for name in dt_names:\n",
    "    somdata = groupdfs[name].copy()\n",
    "    somdata.set_index('date', inplace=True)\n",
    "    monthly = somdata.resample('M').pcs_m.median()\n",
    "    monthly_median.update({name:[monthly, somdata]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "colors = ['dodgerblue', 'salmon', 'teal']\n",
    "\n",
    "# results by lake\n",
    "for i,name in enumerate(dt_names):\n",
    "    data = monthly_median[name][1]\n",
    "    sns.scatterplot(data=data, x=data.index,  y='pcs_m', label=name[:-3], color=colors[i], ax=axs[0])\n",
    "for i,name in enumerate(dt_names):\n",
    "    data = monthly_median[name][0]\n",
    "    sns.lineplot(data=data, x=data.index,  y=data, label=name[:-3], color=colors[i], ax=axs[1])\n",
    "axs[0].xaxis.set_minor_locator(days)\n",
    "axs[0].xaxis.set_major_formatter(mths_fmt)\n",
    "axs[0].xaxis.set_major_locator(months)\n",
    "axs[0].tick_params(which='major', pad=10)\n",
    "axs[0].set_xlabel(\"\")\n",
    "labels, handles = axs[0].get_legend_handles_labels()\n",
    "axs[0].legend(labels, handles)\n",
    "axs[0].set_title(F\"Figure {figure_num}:survey results: {start_date} - {end_date}\", **title_k)\n",
    "figure_num += 1\n",
    "    \n",
    "axs[1].set_title(F\"Figure {figure_num}:median monthly survey results: {start_date} - {end_date}\", **title_k)\n",
    "figure_num +=1\n",
    "axs[1].xaxis.set_minor_locator(days)\n",
    "axs[1].xaxis.set_major_formatter(mths_fmt)\n",
    "axs[1].xaxis.set_major_locator(months)\n",
    "axs[1].tick_params(which='major', pad=10)\n",
    "axs[1].set_xlabel(\"\")\n",
    "labels, handles = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend(labels, handles)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,len(dt_names), figsize=(12,5))\n",
    "\n",
    "\n",
    "for i,name in enumerate(dt_names):\n",
    "    data = groupdfs[name]\n",
    "    sns.histplot(\n",
    "        data=data,\n",
    "        x=data.pcs_m,\n",
    "        label=name[:-3],\n",
    "        color=colors[i],\n",
    "        stat='count',\n",
    "        ax=axs[i])\n",
    "    axs[i].set_title(F\"Figure {figure_num}: {name[:-3]}\", **title_k)\n",
    "    figure_num += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#008891\">Definition of significant values</span>\n",
    "\n",
    "Significant values are those survey values that are equal to or exceed the 90th percentile of all survey results for the defined code.\n",
    "\n",
    "(table 3, fig 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='left', fontsize=10, colWidths = [0.4, 0.3, 0.3])\n",
    "\n",
    "for i,name in enumerate(dt_names):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10,6))\n",
    "    \n",
    "    # table of significant events\n",
    "    axs[0].add_table(mpl.table.table(\n",
    "        cellText=events_data[name].values,\n",
    "        colLabels=events_data[name].columns,\n",
    "        colColours=['antiquewhite' for col in events_data[name].columns],\n",
    "        ax=axs[0],\n",
    "        **tablecenter_k))\n",
    "#     axs[0].set_fontsize(12)\n",
    "    axs[0].grid(False)\n",
    "    axs[0].spines[\"top\"].set_visible(False)\n",
    "    axs[0].spines[\"right\"].set_visible(False)\n",
    "    axs[0].spines[\"bottom\"].set_visible(False)\n",
    "    axs[0].spines[\"left\"].set_visible(False)\n",
    "    axs[0].tick_params(**tabtickp_k)\n",
    "    axs[0].set_title(F\"Table {table_num}: {name[:-3]} significant events per lake\", **titler_k)\n",
    "    table_num+=1\n",
    "    \n",
    "#     significant events by lake\n",
    "    ax2 = sns.scatterplot(data=groupdfs[name],\n",
    "                          x='water_name',\n",
    "                          y='pcs_m',\n",
    "                          hue='water_name',\n",
    "                          style='significant',\n",
    "                          s=120, ax=axs[1],\n",
    "                          palette='husl',\n",
    "                          markers={True:'X', False:'s'})\n",
    "    ax2.xaxis.set_tick_params(rotation=45)\n",
    "    for tick in ax.xaxis.get_majorticklabels():\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    ax2.set_xlabel(\"\")\n",
    "    ax2.set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(handles[9:], labels[9:])\n",
    "    ax2.set_title(F\"Figure {figure_num}: {name[:-3]} significant events\", **titler_k)\n",
    "    figure_num += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "#     figfourfile = F\"{project_directory}/figurefourtablethree.jpg\"\n",
    "#     files_generated.append(figfourfile)\n",
    "#     plt.savefig(figfourfile,dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#008891\">Geographic scope</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data for a map\n",
    "# map median pcs_m to location\n",
    "new_map_data = {}\n",
    "for i,name in enumerate(dt_names):\n",
    "    somdata = groupdfs[name]\n",
    "    \n",
    "    \n",
    "    median_map = somdata.groupby('location').pcs_m.median().copy()\n",
    "\n",
    "    # identify the beaches with no code:\n",
    "    nogpi = somdata[somdata.pcs_m == 0]\n",
    "    noGpibeaches = dfBeaches.loc[dfBeaches.index.isin(nogpi.location.unique())].copy()\n",
    "    # apply the map\n",
    "#     noGpibeaches['pcs_m'] = noGpibeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "    # repeat for the places where code was found:\n",
    "    hasGpi = somdata[somdata.pcs_m > 0]\n",
    "    gpbeaches = dfBeaches.loc[dfBeaches.index.isin(hasGpi.location.unique())].copy()\n",
    "    gpbeaches['pcs_m'] = gpbeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "    # repeat one more time for significant events:\n",
    "    sign = somdata[somdata.significant == True]\n",
    "    gpsbeaches = dfBeaches.loc[dfBeaches.index.isin(sign.location.unique())].copy()\n",
    "    gpsbeaches['pcs_m'] = gpsbeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "    # call gpd on datafarames\n",
    "    gbeaches = gpd.GeoDataFrame(noGpibeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(noGpibeaches.longitude, noGpibeaches.latitude))\n",
    "    gpibeaches = gpd.GeoDataFrame(gpbeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(gpbeaches.longitude, gpbeaches.latitude))\n",
    "    gpsigbeaches = gpd.GeoDataFrame(gpsbeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(gpsbeaches.longitude, gpsbeaches.latitude))\n",
    "\n",
    "    # reproject to correct crs\n",
    "    gdbeaches = gbeaches.to_crs(gdf.crs)\n",
    "    gpibeaches = gpibeaches.to_crs(gdf.crs)\n",
    "    gpsigbeaches = gpsigbeaches.to_crs(gdf.crs)\n",
    "    ma_p_data = {name:[gdbeaches, gpibeaches, gpsigbeaches]}\n",
    "    \n",
    "    new_map_data.update(ma_p_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_map_data['kiosk waste_dt'][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green']\n",
    "markers = ['p', 'x', 'o']\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,12))\n",
    "axs.set_aspect('equal')\n",
    "\n",
    "# plot the geo data\n",
    "gdfch.plot(ax=axs, zorder=0, color='white', edgecolor='black', linewidth=0.26)\n",
    "gdf.plot(ax=axs, zorder=1, color='white', edgecolor='black', label='riparian coumminities', linewidth=0.26)\n",
    "gdflakes.plot(ax=axs, zorder=2, color='dodgerblue', edgecolor='white', linewidth=0.26)\n",
    "for j, name in enumerate(dt_names[:2]):\n",
    "    somdata = new_map_data[name][1]\n",
    "    somdata.plot(ax=axs, zorder=3, color=colors[j], edgecolor='white',marker=markers[j], alpha=0.8, label=F\"{name[:-3]}\", markersize=(140-(10*i)))\n",
    "#         .plot(ax=axs, zorder=3, color='yellow', edgecolor='red',marker='o', label=F\"{code} found\", markersize=80)\n",
    "# gpsigbeaches.plot(ax=axs, zorder=4, color='red', edgecolor='red',marker='o', label=F\"{code} significant\", markersize=80)\n",
    "\n",
    "# get and set map bounds\n",
    "minx, miny, maxx, maxy = gdfch.total_bounds\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "axs.set_title(F\"Map 2: {group_one_name} location of significant events {end_date}.\", **title_k)\n",
    "axs.set_xlim(minx, maxx)\n",
    "axs.set_ylim(miny, maxy)\n",
    "\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "maptwofile = F\"{project_directory}/maptwo.jpg\"\n",
    "files_generated.append(maptwofile)\n",
    "plt.savefig(maptwofile, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\">Lac Léman results and conclusions</span>\n",
    "table 4, figure 5, table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make summary of data and put to table:\n",
    "leman_data = {k:v.loc[v.water_name == lake] for k,v in groupdfs.items()}\n",
    "# summarize the total pcs/m per survey:\n",
    "# use pd.describe and omit the first element (count):\n",
    "leman_summary = [[np.round(leman_data['kiosk waste_dt'].pcs_m.describe()[i], 2)] for i in leman_data['kiosk waste_dt'].pcs_m.describe().index[1:]]\n",
    "# use the index for the row labels:\n",
    "dtotal_rowlabels=leman_data['kiosk waste_dt'].pcs_m.describe().index[1:]\n",
    "\n",
    "# repeat for the code o\n",
    "g112Dt_summary = [[np.round(leman_data['construction waste_dt'].pcs_m.describe()[i], 2)] for i in leman_data['construction waste_dt'].pcs_m.describe().index[1:]]\n",
    "g112Dt_rowlabels=leman_data['construction waste_dt'].pcs_m.describe().index[1:]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,8))\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='left', fontsize=10, colWidths = [1])\n",
    "\n",
    "anax = axs[0].add_table(mpl.table.table(cellText=leman_summary,rowLabels=dtotal_rowlabels, colLabels=['Summary'],colColours=['antiquewhite' for i in np.arange(1)], rowColours=['antiquewhite' for i in np.arange(len(dtotal_rowlabels))],  ax=axs[0], **tablecenter_k))\n",
    "anax.set_fontsize(12)\n",
    "axs[0].grid(False)\n",
    "axs[0].spines[\"top\"].set_visible(False)\n",
    "axs[0].spines[\"right\"].set_visible(False)\n",
    "axs[0].spines[\"bottom\"].set_visible(False)\n",
    "axs[0].spines[\"left\"].set_visible(False)\n",
    "axs[0].tick_params(**tabtickp_k)\n",
    "axs[0].set_title(F\"Survey totals\", **titler_k)\n",
    "\n",
    "\n",
    "anax1 = axs[1].add_table(mpl.table.table(cellText=g112Dt_summary,rowLabels=g112Dt_rowlabels, colLabels=['Summary'],colColours=['antiquewhite' for i in np.arange(1)], rowColours=['antiquewhite' for i in np.arange(len(g112Dt_rowlabels))],  ax=axs[1], **tablecenter_k))\n",
    "anax.set_fontsize(12)\n",
    "axs[1].grid(False)\n",
    "axs[1].spines[\"top\"].set_visible(False)\n",
    "axs[1].spines[\"right\"].set_visible(False)\n",
    "axs[1].spines[\"bottom\"].set_visible(False)\n",
    "axs[1].spines[\"left\"].set_visible(False)\n",
    "axs[1].tick_params(**tabtickp_k)\n",
    "axs[1].set_title(F\"{code} survey totals\", **titler_k)\n",
    "\n",
    "\n",
    "plt.suptitle(F\"table 4: Key values {lake} survey results, n={len(leman_data['kiosk waste_dt'])}\", x=.5, y=1, ha='center', fontsize=(14))\n",
    "plt.tight_layout()\n",
    "# tablefourfile = F\"{project_directory}/tablefour.jpg\"\n",
    "# files_generated.append(tablefourfile)\n",
    "# plt.savefig(tablefourfile, dpi=300)\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(12,12))\n",
    "\n",
    "# results grouped by beach\n",
    "ax = sns.scatterplot(data=leman_data['kiosk waste_dt'], x='location',  y='pcs_m', style='significant', markers={True:'X', False:'s'}, hue='location', marker=\"s\", s=80, palette='husl', ax=axs[0,0])\n",
    "ax.xaxis.set_tick_params(rotation=45)\n",
    "for tick in ax.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.get_legend().remove()\n",
    "ax.set_title(F\"Figure {figure_num} : {dt_names[0][:-3]} pcs/m per location\", **title_k)\n",
    "ax.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "figure_num += 1\n",
    "\n",
    "# results by date\n",
    "ax2 = sns.scatterplot(data=leman_data['construction waste_dt'], x='location',  y='pcs_m', style='significant', markers={True:'X', False:'s'}, hue='location', marker=\"s\", s=80, palette='husl', ax=axs[0,1])\n",
    "ax2.xaxis.set_tick_params(rotation=45)\n",
    "for tick in ax2.xaxis.get_majorticklabels():\n",
    "    tick.set_horizontalalignment(\"right\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.get_legend().remove()\n",
    "ax2.set_title(F\"Figure {figure_num} : {dt_names[1][:-3]} pcs/m per location\", **title_k)\n",
    "ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "figure_num += 1\n",
    "# ax2 = sns.scatterplot(data=leman_data['kiosk waste_dt'], x='date', y='pcs_m', hue='location', style='significant',s=80, palette='husl', markers={True:'X', False:'s'},ax=axs[0,1])\n",
    "# ax2.set_title(F\"{code} Lac Léman survey results\", **title_k)\n",
    "# ax2.xaxis.set_minor_locator(days)\n",
    "# ax2.xaxis.set_major_formatter(mths_fmt)\n",
    "# ax2.xaxis.set_major_locator(months)\n",
    "# ax2.tick_params(which='major', pad=10)\n",
    "# ax2.set_xlabel(\"\")\n",
    "# ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "\n",
    "\n",
    "# table of significant events\n",
    "ax3 = sns.ecdfplot(data=leman_data['kiosk waste_dt'], x='pcs_m',label='kiosk waste', ax=axs[1,0])\n",
    "ax3 = sns.ecdfplot(data=leman_data['construction waste_dt'], x='pcs_m', label='construction waste',  ax=axs[1,0])\n",
    "ax3.set_title(F\"Figure {figure_num} :ECDF pieces per meter\", **title_k)\n",
    "ax3.set_xlabel(\"pieces per meter\", **xlab_k)\n",
    "ax3.set_ylabel(\"Ratio of samples\", **ylab_k)\n",
    "labels, handles = ax3.get_legend_handles_labels()\n",
    "ax3.legend(labels, handles)\n",
    "figure_num += 1\n",
    "# to be decided\n",
    "ax4 = sns.ecdfplot(data=leman_data['kiosk waste_dt'], x='p_total',label='kiosk waste', ax=axs[1,1])\n",
    "ax4 = sns.ecdfplot(data=leman_data['construction waste_dt'], x='p_total', label='construction waste',  ax=axs[1,1])\n",
    "ax4.set_title(F\"Figure {figure_num} :ECDF percent of daily total\", **title_k)\n",
    "ax4.set_xlabel(\"percent of daily total\", **xlab_k)\n",
    "ax4.set_ylabel(\"Ratio of samples\", **ylab_k)\n",
    "labels, handles = ax4.get_legend_handles_labels()\n",
    "ax4.legend(labels, handles)\n",
    "figure_num += 1\n",
    "\n",
    "plt.suptitle(F\"Figure 5: Lac Léman Disrtibution of {code} pcs/m, n={len(leman_data['kiosk waste_dt'])}\", x=.98, y=1, ha='right', fontsize=(14))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# figfivefile = F\"{project_directory}/figurefive.jpg\"\n",
    "# files_generated.append(figfivefile)\n",
    "# plt.savefig(figfivefile, dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\">Use and distribution</span>\n",
    "(map 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitText(string, w=3):\n",
    "    words = string.split()\n",
    "    g = [' '.join(words[i: i + w]) for i in range(0, len(words), w)]\n",
    "    a_stack =  '\\n'.join(g)\n",
    "    return a_stack\n",
    "dfCodes['stacked'] = dfCodes.description.map(lambda x:splitText(x, w=3))\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='left', fontsize=10, colWidths = [0.2, 0.6, 0.2])\n",
    "\n",
    "for i, group in enumerate(project_groups):\n",
    "    print(group)\n",
    "    height=(len(group)+1)*1.5\n",
    "    fig, axs = plt.subplots(figsize=(6, height))\n",
    "    som_data = dfCodes[dfCodes.code.isin(group)][['code', 'stacked', 'material']]\n",
    "    a = plt.table(cellText=som_data.values,\n",
    "                  colLabels=som_data.columns,\n",
    "                  colColours=['antiquewhite' for col in data.columns],\n",
    "                  **tablecenter_k)\n",
    "    axs.add_table(a)\n",
    "    axs.grid(False)\n",
    "    axs.spines[\"top\"].set_visible(False)\n",
    "    axs.spines[\"right\"].set_visible(False)\n",
    "    axs.spines[\"bottom\"].set_visible(False)\n",
    "    axs.spines[\"left\"].set_visible(False)\n",
    "    axs.tick_params(**tabtickp_k)\n",
    "    axs.set_title(F\"Table {table_num}: Regional survey results, {dt_names[i][:-3]}\", **titler_k)\n",
    "    table_num += 1\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the beaches for the lake in question\n",
    "lemanbeaches =  dfBeaches.loc[dfBeaches.water_name == lake].copy()\n",
    "\n",
    "# find the ones that have zero for the code quantity or pcs_m:\n",
    "noGpibeaches = lemanbeaches.loc[lemanbeaches.index.isin(noGpi.location.unique())].copy()\n",
    "\n",
    "# make a map of the location and the median pcs_m for that location\n",
    "median_map = g112Df.groupby('location').pcs_m.median().copy()\n",
    "\n",
    "# map location of no gpi to the median value in g112Df:\n",
    "noGpibeaches['pcs_m'] = noGpibeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "# get the ones that have greater than zero for the code:\n",
    "gpbeaches = lemanbeaches.loc[lemanbeaches.index.isin(hasGpi.location.unique())].copy()\n",
    "\n",
    "# map location of gpbeaches to the median value in g112Df:\n",
    "gpbeaches['pcs_m'] = gpbeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "gpsbeaches = lemanbeaches.loc[lemanbeaches.index.isin(p_dt90_s.location.unique())].copy()\n",
    "gpsbeaches['pcs_m'] = gpsbeaches.index.map(lambda x: median_map[x])\n",
    "\n",
    "# make geodata frames\n",
    "gbeaches = gpd.GeoDataFrame(noGpibeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(noGpibeaches.longitude, noGpibeaches.latitude))\n",
    "gpibeaches = gpd.GeoDataFrame(gpbeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(gpbeaches.longitude, gpbeaches.latitude))\n",
    "gpsigbeaches = gpd.GeoDataFrame(gpsbeaches, crs='EPSG:4326', geometry=gpd.points_from_xy(gpsbeaches.longitude, gpsbeaches.latitude))\n",
    "\n",
    "# get shape files \n",
    "leman_com = gpd.read_file('resources/shapes/leman_communesx.shp')\n",
    "leman_filled = gpd.read_file('resources/shapes/leman_filledx.shp')\n",
    "leman_ints = gpd.read_file('resources/shapes/leman_intersectsx.shp')\n",
    "\n",
    "# if you have distribution points or user points load them here:\n",
    "# gpi_sp = gpd.read_file('resources/shapes/gpi_spointsx.shp')\n",
    "\n",
    "gdbeaches = gbeaches.to_crs(leman_ints.crs)\n",
    "gpibeaches = gpibeaches.to_crs(leman_ints.crs)\n",
    "gpsigbeaches = gpsigbeaches.to_crs(leman_ints.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(figsize=(12,12))\n",
    "axs.set_aspect('equal')\n",
    "\n",
    "# plot the data frames\n",
    "leman_ints.plot(ax=axs, zorder=1, color='dodgerblue', linewidth=0.26)\n",
    "leman_filled.plot(ax=axs, zorder=2, color='dodgerblue', edgecolor='dodgerblue', label='riparian coumminities', linewidth=0.26)\n",
    "leman_com.plot(ax=axs, zorder=0,  color='white', edgecolor='black', linewidth=0.26)\n",
    "gdbeaches.plot(ax=axs, zorder=3, color='slategray', edgecolor='black',marker='o', label=F\"{code} not found\", markersize=markerSize)\n",
    "gpibeaches.plot(ax=axs, zorder=4, color='yellow', edgecolor='red',marker='o', label=F\"{code} found\", markersize=markerSize)\n",
    "gpsigbeaches.plot(ax=axs, zorder=5, color='red', edgecolor='red',marker='o', label=F\"{code} significant\", markersize=markerSize)\n",
    "\n",
    "# these are distribution or user points, they are on top:\n",
    "# gpi_sp.plot(ax=axs, zorder=6, color='red', edgecolor='red',marker='x', label=F\"{code} supplier/user\", markersize=markerSize) \n",
    "\n",
    "\n",
    "# set min max\n",
    "minx, miny, maxx, maxy = leman_ints.total_bounds\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "axs.set_title(F\"map 3: {lake} survey locations and {code} suppliers/users {end_date}.\", **title_k)\n",
    "axs.set_xlim(minx, maxx)\n",
    "axs.set_ylim(miny, maxy)\n",
    "\n",
    "# do work on legend if need\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "mapthreefile = F\"{project_directory}/mapthree.jpg\"\n",
    "files_generated.append(mapthreefile)\n",
    "plt.savefig(mapthreefile, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the beach, the lake and the name of each municipality\n",
    "# considered in this report\n",
    "\n",
    "data = beaches[['water_name', 'location', 'city']].sort_values(by='water_name')\n",
    "data.rename(columns={'water_name':'Lake', 'location':'Location','city':'Municipality'}, inplace=True)\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=14)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,32))\n",
    "ax1= ax.add_table(mpl.table.table(cellText=data.values, colLabels=data.columns,colColours=['antiquewhite' for col in data.columns], ax=ax, **tablecenter_k))\n",
    "ax.grid(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.tick_params(**tabtickp_k)\n",
    "ax.set_title(F\"annex a: Municipalities considered in this report\", **titler_k)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_styling():\n",
    "    styles = open(F\"{project_directory}/custom.css\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
